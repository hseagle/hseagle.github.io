{"categories":[{"title":"citus","uri":"https://hseagle.github.io/categories/citus/"},{"title":"config","uri":"https://hseagle.github.io/categories/config/"},{"title":"Debezium","uri":"https://hseagle.github.io/categories/debezium/"},{"title":"IMV","uri":"https://hseagle.github.io/categories/imv/"},{"title":"Materialize","uri":"https://hseagle.github.io/categories/materialize/"},{"title":"Patroni","uri":"https://hseagle.github.io/categories/patroni/"},{"title":"PostgreSQL","uri":"https://hseagle.github.io/categories/postgresql/"},{"title":"raft","uri":"https://hseagle.github.io/categories/raft/"}],"posts":[{"content":"Materialize是一款或者说当前市面上唯一一款支持实时增量视图的开源软件，在Materialize 0.9.0版本之后，支持以PostgreSQL为数据源，利用PostgreSQL的logical replication读取PG最新数据，本文演示如何把两者结合在一起，并利用简单的Python脚本，把最新的聚合结果写回到PostgreSQL。\nPostgreSQL PostgreSQL中的wal_level要设置为logical, 创建表并调整replica identity为FULL, 以表person为例。\ncreate table person(name varchar(32), age int, int gender, primary key(name)); alter table person replica identity full;  创建publication, 并添加表。\ncreate publication pg_mz_publication; alter publication pg_mz_publication add table person;  检测publication中有哪些表会进行逻辑复制。\nselect * from pg_publication_tables;  Materialize Source Materialize中三个主要概念，分别是Source/View/Sink.\nsource表示从哪裡读取数据，当前支持kafka/postgresql/avro文件等。\nview主要用于对Source进行分析和处理的逻辑。\nsink用于将view中变化的结果存储起来, 当前和kafka的整合较好。\ncreate materialized source mz_pg_source from postgres connection 'host=localhost user=postgres dbname=postgres' publication 'pg_mz_publication';  创建视图 create views from source mz_pg_source (person as person);  创建分析视图 create materialized view stat_person as select gender, count(*) from person;  视图变化结果存储到 PostgreSQL 使用tail命令可以捕获视图中最新的变化数据， 为了及时的把数据写入到Sink, 使用timeout参数。\ndef watch_mv_change(mv_name): mz_conn = psycopg2.connect(dsn) dynamic_insert_sql = generate_insert_sql(mv_name) try: l_rows = [] with mz_conn.cursor() as cur: cur.execute('declare c cursor for tail {}'.format(mv_name)) while True: cur.execute(\u0026quot;fetch all c with (timeout='100ms')\u0026quot;) l_rows.clear() for row in cur: if row[1] == 1: l_row = list(row) l_row.pop(0) l_row.pop(0) l_rows.append(tuple(l_row)) if len(l_rows) \u0026gt; 200: psycopg2.extras.execute_batch(pg_cur,dynamic_insert_sql, l_rows) pg_conn.commit() l_rows.clear() if len(l_rows) \u0026gt; 0: psycopg2.extras.execute_batch(pg_cur,dynamic_insert_sql, l_rows) pg_conn.commit() except Exception as ex: print(mv_name) print(ex) pass ","id":0,"section":"posts","summary":"\u003cp\u003eMaterialize是一款或者说当前市面上唯一一款支持实时增量视图的开源软件，在Materialize 0.9.0版本之后，支持以PostgreSQL为数据源，利用PostgreSQL的logical replication读取PG最新数据，本文演示如何把两者结合在一起，并利用简单的Python脚本，把最新的聚合结果写回到PostgreSQL。\u003c/p\u003e","tags":["Materialize"],"title":"PostgreSQL和Materialize构建实时增量视图","uri":"https://hseagle.github.io/2021/11/pg-materializeinc/","year":"2021"},{"content":"Debezium是一款非常活跃的数据同步工具， 本文介绍如何基于Kafka Connect和Debezium将PostgreSQL中的数据同步复制到Kafka.\ndebezium实时同步PostgreSQL数据到Kafka PostgreSQL配置 修改postgresql.conf中有关 wal_level 级别， 由默认的 replica 调整为 logical, 该配置项修改后需要重启PostgreSQL进程。\nwal_level=logical  安装redpanda PostgreSQL数据实时变化过程中，有两类基本数据，一种是表中的数据的变更，另一种是表结构变更的信息。\nKakfa用于存储表中的数据，Schema Registry用于保存表的结构数据。\nKafka解决方案中涉及到的组件较多，比如需要部署zookeeper, kafka和schema registry，这让整个部署和维护链条都很长。Redpanad是为了解决部署链条过长的痛点而诞生的一个新开源项目，兼容kafka api， 但采用raft协议，去除了zookeeper信赖，同时支持schema registry。\ndocker run \\ --name=redpanda-1 \\ --network host \\ --detach \\ --rm \\ vectorized/redpanda:v21.9.5 start \\ --overprovisioned \\ --smp 1 \\ --memory 1G \\ --reserve-memory 0M \\ --node-id 0 \\ --check=false \\ --pandaproxy-addr 0.0.0.0:8082 \\ --advertise-pandaproxy-addr 127.0.0.1:8082 \\ --kafka-addr 0.0.0.0:9092 \\ --advertise-kafka-addr 127.0.0.1:9092 \\ --set \u0026quot;redpanda.enable_transactions=true\u0026quot; \\ --set \u0026quot;redpanda.enable_idempotence=true\u0026quot;  安装kafka-connect 利用docker来下载kafka-connect及其信赖。\ndocker pull debezium/connect  运行debezium/connect\ndocker run -it --name connect -p 8083:8083 -e GROUP_ID=1 -e CONFIG_STORAGE_TOPIC=my-connect-configs -e OFFSET_STORAGE_TOPIC=my-connect-offsets -e ADVERTISED_HOST_NAME=$(echo $DOCKER_HOST | cut -f3 -d'/' | cut -f1 -d':') --link zookeeper:zookeeper --link kafka:kafka debezium/connect  将connect目录从docker container复制到host机器\ndocker cp connect:/kafka /tmp  config/connect-distributed.properties\nbootstrap.servers=127.0.0.1:9092 group.id=2 key.converter=org.apache.kafka.connect.json.JsonConverter value.converter=org.apache.kafka.connect.json.JsonConverter key.converter.schemas.enable=true value.converter.schemas.enable=true offset.storage.topic=my-connect-offsets offset.storage.replication.factor=1 config.storage.topic=my-connect-configs config.storage.replication.factor=1 status.storage.topic=my_connect_statuses status.storage.replication.factor=1 offset.flush.interval.ms=60000 rest.host.name=127.0.0.1 rest.port=8083 rest.advertised.host.name=127.0.0.1 rest.advertised.port=8083 plugin.path=/usr/share/java,/etc/kafka-connect/jars,/opt/bigdata/kafka-connect/connect internal.value.converter=org.apache.kafka.connect.json.JsonConverter offset.flush.timeout.ms=5000 internal.key.converter=org.apache.kafka.connect.json.JsonConverter task.shutdown.graceful.timeout.ms=10000  运行kafka connect\nbin/connect-distributed.sh config/connect-distributed.properties  注册connector register-postgres-avro.json\n{ \u0026quot;name\u0026quot;: \u0026quot;anticrawler-connector-inst\u0026quot;, \u0026quot;config\u0026quot;: { \u0026quot;connector.class\u0026quot;: \u0026quot;io.debezium.connector.postgresql.PostgresConnector\u0026quot;, \u0026quot;tasks.max\u0026quot;: \u0026quot;1\u0026quot;, \u0026quot;database.hostname\u0026quot;: \u0026quot;127.0.0.1\u0026quot;, \u0026quot;database.port\u0026quot;: \u0026quot;5432\u0026quot;, \u0026quot;database.user\u0026quot;: \u0026quot;postgres\u0026quot;, \u0026quot;database.dbname\u0026quot; : \u0026quot;postgres\u0026quot;, \u0026quot;database.server.name\u0026quot;: \u0026quot;dbserver0\u0026quot;, \u0026quot;publication.autocreate.mode\u0026quot;:\u0026quot;filtered\u0026quot;, \u0026quot;schema.include.list\u0026quot;: \u0026quot;inst\u0026quot;, \u0026quot;table.include.list\u0026quot;: \u0026quot;inst\\\\.mock_.*,prim\\\\.partitioned_demo_p20.*\u0026quot;, \u0026quot;plugin.name\u0026quot;:\u0026quot;pgoutput\u0026quot;, \u0026quot;heartbeat.interval.ms\u0026quot;: \u0026quot;5\u0026quot;, \u0026quot;database.history.kafka.bootstrap.servers\u0026quot;: \u0026quot;127.0.0.1:9092\u0026quot;, \u0026quot;database.history.kafka.topic\u0026quot;: \u0026quot;schema-changes.anticrawler\u0026quot;, \u0026quot;key.converter\u0026quot;: \u0026quot;io.confluent.connect.avro.AvroConverter\u0026quot;, \u0026quot;value.converter\u0026quot;: \u0026quot;io.confluent.connect.avro.AvroConverter\u0026quot;, \u0026quot;key.converter.schema.registry.url\u0026quot;: \u0026quot;http://127.0.0.1:8081\u0026quot;, \u0026quot;value.converter.schema.registry.url\u0026quot;: \u0026quot;http://127.0.0.1:8081\u0026quot;, \u0026quot;transforms\u0026quot;:\u0026quot;Reroute\u0026quot;, \u0026quot;transforms.Reroute.type\u0026quot;:\u0026quot;io.debezium.transforms.ByLogicalTableRouter\u0026quot;, \u0026quot;transforms.Reroute.topic.regex\u0026quot;: \u0026quot;(.*)partitioned_demo(.*)\u0026quot;, \u0026quot;transforms.Reroute.topic.replacement\u0026quot;: \u0026quot;$1partitioned_demo\u0026quot;, \u0026quot;transforms.Reroute.key.enforce.uniqueness\u0026quot;:\u0026quot;false\u0026quot; } }  利用connect的rest api来注册connector\ncurl -i -X POST -H \u0026quot;Accept:application/json\u0026quot; -H \u0026quot;Content-Type:application/json\u0026quot; http://127.0.0.1:8083/connectors/ -d @register-postgres-avro.json  状态检测 在PG侧验证逻辑复制的进度\nselect * from pg_stat_replication; select * from pg_replication_slots;  redpanda侧查看topic是否已经创建\nrpk topic list  如果topic已经创建，接下来可以尝试观察一下同步的数据内容\nrpk topic consume dbserver1.inst.tblname ","id":1,"section":"posts","summary":"\u003cp\u003eDebezium是一款非常活跃的数据同步工具， 本文介绍如何基于Kafka Connect和Debezium将PostgreSQL中的数据同步复制到Kafka.\u003c/p\u003e","tags":["PG逻辑复制"],"title":"Debezium同步PostgreSQL数据到Kafka","uri":"https://hseagle.github.io/2021/11/pg-debezium/","year":"2021"},{"content":"PostgreSQL运维中，遇到一两个没预期到故障，应该不是难事:(，比如这两天就刚解决掉一个磁盘无故写爆的案例。\nautovacuum PostgreSQL实现MVCC的机制需要有一个vacuum的过程，为了减弱人工介入的必要性，在PG Server启动时，默认会自动拉起autovacuum。\n有了autovacuum并不意味着可以高枕无忧， 在某些情况下，autovacuum无法清除dead tuples，磁盘无法有效清理，最终写爆。\n可能一 长时间的Query 如果某些Query运行了很长时间，比如几个小时甚至几天，那么这些Query就会导致autovacuum无法清除垃圾数据。\n假设这些查询是在T0时刻启动，在T1时刻，有数据被删除或者更新，在T2时刻，autovacuum开始进行清理，在这个新启动的清除过程中，只有T0时刻之前的dead tuples会被有效清理，而在T1时刻被删除的数据无法被清除，因为T0时刻的查询依然需要这些数据。\n要解决这个问题，就必须终止长时间的query。一种是等查询自然完成，另一种是显式的kill, 假设某query的pid是123, 那么使用 pg_terminate_backend 或 pg_cancel_backend\nselect pg_terminate_backend(query_pid)  可能二 废弃的replication slots 如果某些subscriptor订阅了CDC消息，但是subscriber异常退出后，并没有删除对应的replication slots，那么由于数据没有被消费，所以dead tuples也会被一直保留。\n用 pg_drop_replication_slot() 删除废弃不用的复制槽位。\n可能三 僵死或处于孤儿状态的 prepared transaction 在两阶段提交(two-phase commit)中, 需要在第一步创建prepared transaction, 如果因为某种原因prepared transaction一直没有结束，那么从创建这个预事务之后的所有dead tuples无法得到清除。\n处理办法，先利用视图 pg_prepared_xacts 列出有哪些僵死的预事务，然后用 rollback prepared transaction_id 来回退该事务。\nrollback prepared 链接有详细的示例说明\n","id":2,"section":"posts","summary":"\u003cp\u003ePostgreSQL运维中，遇到一两个没预期到故障，应该不是难事:(，比如这两天就刚解决掉一个磁盘无故写爆的案例。\u003c/p\u003e","tags":null,"title":"PostgreSQL故障排查 -- 磁盘写满, autovacuum不香了","uri":"https://hseagle.github.io/2021/10/pg-autovacuum-failed/","year":"2021"},{"content":"psycopg2是PostgreSQL非常好的Python Client Library, 本文通过爬取上市公司的基础数据来演示如何使用\n表结构 create table if not exists company( symbol varchar(32), --股票代码 name varchar(128), --公司名称 ceo varchar(64), --法人代表, capitol varchar(64), --注册资金 addr varchar(128), --注册地址 establish_date date, --成立日期 listing_date date, --上市日期, scope text, -- 经营范围 profile text, --公司简介 primary key(symbol) );  数据爬取 python package安装\npip install selenium geckodriver psycopg2 pandas  东方财富提供的上市公司数据很齐全，下面的代码演示如何将 公司简介 这张表中的数据抽取出来并存入到数据库中。\n## filename: stock_web_crawler.py import akshare as ak from selenium import webdriver from selenium.webdriver.common.by import By from selenium.webdriver.common.keys import Keys from selenium.webdriver.support.ui import Select from selenium.common.exceptions import NoSuchElementException from selenium.common.exceptions import NoAlertPresentException import unittest, time, re from selenium.webdriver.firefox.options import Options as FirefoxOptions import psycopg2 import pandas as pd options = webdriver.FirefoxOptions() options.headless = True f_df = ak.stock_zh_a_spot_em() stock_code_df = f_df['代码'] insert_sql = \u0026quot;\u0026quot;\u0026quot;insert into company(symbol, name, ceo, addr, capitol, establish_date, listing_date, scope, profile) values(%(symbol)s, %(name)s, %(ceo)s, %(addr)s, %(capitol)s, %(establish_date)s, %(listing_date)s,%(scope)s,%(profile)s)\u0026quot;\u0026quot;\u0026quot; pg_conn_str = \u0026quot;host='localhost' port='5434' user='dba' dbname='postgres'\u0026quot; conn = psycopg2.connect(pg_conn_str) for i in stock_code_df.sort_values().head(10): driver = webdriver.Firefox(options=options) driver.get(\u0026quot;http://data.eastmoney.com/stockdata/{}.html\u0026quot;.format(i)) html_text = driver.page_source dfs = pd.read_html(html_text) co_df = dfs[32] with conn.cursor() as cur: stock_dict=({\u0026quot;symbol\u0026quot;: i, \u0026quot;name\u0026quot;:co_df.iloc[0][1],\u0026quot;ceo\u0026quot;:co_df.iloc[0][3], 'addr':co_df.iloc[1][1], 'capitol': co_df.iloc[1][3], 'establish_date':co_df.iloc[2][1], 'listing_date':co_df.iloc[2][3], 'scope':co_df.iloc[3][1],'profile':co_df.iloc[4][1]},) cur.executemany(insert_sql, stock_dict) conn.commit() driver.close()  运行上述脚本\npython stock_web_crawler.py  python版本 Python 3.9.1 (default, Dec 11 2020, 14:32:07) [GCC 7.3.0] :: Anaconda, Inc. on linux Type \u0026quot;help\u0026quot;, \u0026quot;copyright\u0026quot;, \u0026quot;credits\u0026quot; or \u0026quot;license\u0026quot; for more information. ","id":3,"section":"posts","summary":"\u003cp\u003epsycopg2是PostgreSQL非常好的Python Client Library, 本文通过爬取上市公司的基础数据来演示如何使用\u003c/p\u003e","tags":["crawler","psycopg2"],"title":"PostgreSQL应用开发之一 -- 爬取上市公司概况数据","uri":"https://hseagle.github.io/2021/10/pg-app-stock/","year":"2021"},{"content":"PostgreSQL常用配置简要说明\nPostgreSQL常用配置    参数 用途 默认值 推荐值 需要重启     网络相关       listen_addresses 监听地址 localhost *表示对所有地址进行监听 是   port 监听端口 5432  是   max_connections 最大网络链接数 100 PG14可以支持大并发链接 是   内存相关       shared_buffers 共享缓存 128MB 设置不高于总体内存的3/4 是   effective_cache_size 允许磁盘缓存的最大容量, 值越大，走索引扫描的可能性越大 4GB 所有内存的1/2 否   maintenance_work_mem 维护操作允许使用的最大内存，操作包括vacuum, create index, and alter table add foreign key 64MB 否    work_mem 查询进程使用的最大内存 4MB Total RAM * 0.25 / max_connections 否   temp_buffers 单个session允许使用的最大缓存 8MB 如果要创建temp表，可以将其设置为较大的值 否   进程数       max_worker_processes 最大后台进程数 8 是    max_parallel_workers 最大并行查询进程总数 8 否    max_parallel_workers_per_gather 单个query的并行进程数 2 否    shared_preload_libraries 预加载扩展 无 \u0026lsquo;pg_statements\u0026rsquo; 是   日志相关       logging_collector 日志开关 on  是   log_directory 日志目录 \u0026lsquo;log\u0026rsquo;  否   log_file_mode 日志文件权限 0600 否    log_truncate_on_rotation 日志回滚 on 否    log_rotation_age 回滚时长 1d  否    推荐站点  pgtune pgconfig ","id":4,"section":"posts","summary":"\u003cp\u003ePostgreSQL常用配置简要说明\u003c/p\u003e","tags":["PG安装"],"title":"PostgreSQL Server常用配置","uri":"https://hseagle.github.io/2021/10/pg-server-config/","year":"2021"},{"content":"Patroni是PostgreSQL可选的高可用方案中接受度最广的一种，特别是在2.0之后，Patroni可以使用raft协议来解决分布式的一致性问题，减少了对etcd或zookeeper的依赖，大大简化了安装和运维, 本篇介绍如何基于raft来构建一个最简单的HA集群。\npatroni安装和准备 用pip来安装patroni，因为使用raft来进行分布式集群管理，所以依赖选择patroni[raft], 如果使用consul则用patroni[consul], 以此类推。\npip install patroni[raft]  因为是以非root用户安装，patroni及patronictl安装在 $HOME/.local/bin\n加载softdog内核模块，避免出现类似错误信息 no such file or directory /dev/watchdog\nsudo modprobe softdog  目录创建和权限修改 PostgreSQL数据目录\nmkdir -p /tmp/patroni_raft/{inst_01,inst_02,inst_03} cd /tmp/patroni_raft chmod -R 0700 inst_01 inst_02 inst_03  raft数据目录\nmkdir -p /tmp/raft/{inst_01,inst_02,inst_03}  patroni配置文件 scope: my-ha-cluster name: pg-1 restapi: listen: 0.0.0.0:8008 connect_address: 127.0.0.1:8008 raft: data_dir: /tmp/raft/inst_01 self_addr: 127.0.0.1:5010 partner_addrs: ['127.0.0.1:5011','127.0.0.1:5012'] bootstrap: dcs: ttl: 30 loop_wait: 10 retry_timeout: 10 maximum_lag_on_failover: 1048576 postgresql: use_pg_rewind: true use_slots: true parameters: wal_level: replica hot_standby: \u0026quot;on\u0026quot; wal_keep_segments: 8 max_wal_senders: 5 max_replication_slots: 5 checkpoint_timeout: 30 initdb: - encoding: UTF8 pg_hba: - host all dba all md5 - host replication repl all md5 users: dba: password: yourcode options: - createrole - createdb repl: password: yourcode options: - replication postgresql: listen: 0.0.0.0:5432 connect_address: 127.0.0.1:5432 data_dir: /tmp/patroni_raft/inst_01 config_dir: /tmp/patroni_raft/inst_01 bin_dir: /usr/local/pgsql/bin authentication: replication: username: repl password: secret superuser: username: dba password: secret parameters: unix_socket_directories: '/tmp/patroni_raft/inst_01'  patroni运行 cp pg-1.yml pg-2.yml cp pg-1.yml pg-3.yml  先把pg-2.yml和pg-3.yml中相应的配置修改一下，主要是节点名称和监听地址以及数据目录。\n修改结束之后，用patroni拉起集群\ncd /tmp/patroni_raft ~/.local/bin/patroni ./pg-1.yml ~/.local/bin/patroni ./pg-2.yml ~/.local/bin/patroni ./pg-3.yml  patroni状态检查 如果一切顺利，集群会被正常拉起， 为进一步确认集群状态，运行如下指令验证。\ncd /tmp/patroni_raft ./local/bin/patronictl -c ./pg-1.yml list  正常的话，会显示如下信息\n+ Cluster: my-ha-cluster (7016961673110130148) ----+-----------+ | Member | Host | Role | State | TL | Lag in MB | +--------+----------------+---------+---------+----+-----------+ | pg-1 | 127.0.0.1:5432 | Replica | running | 1 | 0 | | pg-2 | 127.0.0.1:5433 | Replica | running | 1 | 0 | | pg-3 | 127.0.0.1:5434 | Leader | running | 1 | | +--------+----------------+---------+---------+----+-----------+  连接PostgreSQL 在上面的输出中显示， master是pg-3，监听的端口是5434, 接下来可以连接到master并创建表写入数据进行测试\npsql -Udba -dpostgres -h localhost -p 5434 ","id":5,"section":"posts","summary":"\u003cp\u003ePatroni是PostgreSQL可选的高可用方案中接受度最广的一种，特别是在2.0之后，Patroni可以使用raft协议来解决分布式的一致性问题，减少了对etcd或zookeeper的依赖，大大简化了安装和运维, 本篇介绍如何基于raft来构建一个最简单的HA集群。\u003c/p\u003e","tags":["HA","高可用"],"title":"PostgreSQL HA方案之Patroni[raft]篇","uri":"https://hseagle.github.io/2021/10/pg-patroni-raft/","year":"2021"},{"content":"PostgreSQL是一款MVCC数据库，它的实现机制不同于Oracle和MySQL中的MVCC实现。PG中的实现机制好处是更新和删除效率高，速度快; 负面的效果是需要定期进行数据清理，不然会有数据大量的数据膨胀。\n原理 create extension pageinspect; create table person(name varchar(64), age int); insert into person values('andrew', 22); select xmin, xmax, cmin, cmax, * from person;  当插入一条记录到PostgreSQL表中，系统字段xmax为0, 如果对应的记录被删除或修改，那么该字段为非0,写入的是执行该操作的transaction id, 借助于pageinspect模块，我们可以看到物理页中的真正内容。\ncreate extension if not exists pageinspect; SELECT t_xmin, t_xmax, tuple_data_split('scott.employee'::regclass, t_data, t_infomask, t_infomask2, t_bits) FROM heap_page_items(get_raw_page('scott.employee', 0));  借助于pageinspect, 可以做一个简单试验，看修改记录后，表的物理页中真正的记录形式如何。\nmydb=# insert into person values('andrew', 24); INSERT 0 1 mydb=# SELECT t_xmin, t_xmax, tuple_data_split('person'::regclass, t_data, t_infomask, t_infomask2, t_bits) FROM heap_page_items(get_raw_page('person', 0)); t_xmin | t_xmax | tuple_data_split ---------+--------+------------------------------------- 7397512 | 0 | {\u0026quot;\\\\x0f616e64726577\u0026quot;,\u0026quot;\\\\x18000000\u0026quot;} (1 行记录) mydb=# update person set age = 25 where name = 'andrew'; UPDATE 1 mydb=# SELECT t_xmin, t_xmax, tuple_data_split('person'::regclass, t_data, t_infomask, t_infomask2, t_bits) FROM heap_page_items(get_raw_page('person', 0)); t_xmin | t_xmax | tuple_data_split ---------+---------+------------------------------------- 7397512 | 7397513 | {\u0026quot;\\\\x0f616e64726577\u0026quot;,\u0026quot;\\\\x18000000\u0026quot;} 7397513 | 0 | {\u0026quot;\\\\x0f616e64726577\u0026quot;,\u0026quot;\\\\x19000000\u0026quot;} (2 行记录)  输出结果表明，update操作不会在原有记录上进行修改，而是将原有记录置为无效(xmax设置为非零值)，然后重新写入一条全新记录。\n监控 查看用户表中垃圾记录的数量，并计算和有效记录的比值。\nselect relname, n_live_tup, n_dead_tup, round(n_dead_tup*1.0/n_live_tup, 2) as dead_ratio from pg_stat_user_tables where n_live_tup \u0026gt; 0  mydb-# ; relname | n_live_tup | n_dead_tup | dead_ratio ----------------------+------------+------------+------------ db_sync_cfg_database | 1 | 0 | 0.00 db_sync_cfg_table | 3 | 1 | 0.33 (2 行记录)  调优 触发autovacuum的条件\npg_stat_user_tables.n_dead_tup \u0026gt; (threshold + pg_class.reltuples * scale_factor)  为了尽早触发autovacuum, 可以针对表级别，修改autovacuum配置\nalter table demo set (autovacuum_vacuum_threshold_size=0); alter table demo set (autovacuum_vacuum_scale_factor=0.02);  autovacuum_vacuum_cost_limit autovacuum会带来额外的i/o开销，提升系统负载，对数据库系统的稳定性带来潜在影响，所以PostgreSQL针对autovacuum是有相应的限流设置, 相关的参数有两个\nautovacuum_vacuum_cost_delay autovacuum_vacuum_cost_limit  一般不建议更改 autovacuum_vacuum_cost_delay, 可以把默认的 autovacuum_vacuum_cost_limit 更改为大一点的值，允许触发和执行更多的autovacuum活动。\n","id":6,"section":"posts","summary":"\u003cp\u003ePostgreSQL是一款MVCC数据库，它的实现机制不同于Oracle和MySQL中的MVCC实现。PG中的实现机制好处是更新和删除效率高，速度快; 负面的效果是需要定期进行数据清理，不然会有数据大量的数据膨胀。\u003c/p\u003e","tags":null,"title":"PostgreSQL中的数据膨胀由来及对策","uri":"https://hseagle.github.io/2021/08/pg-mvcc/","year":"2021"},{"content":"pgbench是postgresql进行压测的官方工具，熟悉这一工具的使用，对于后续数据库侧配置参数修改带来的影响，提供了客观的数据参考。\n初始化测试库 create database mydb;  创建表 pgbench -Upostgres -i mydb;  测试 pgbench -Upostgres -c 2 -j 2 -t 10000 mydb;  注释:\n -c 建立链接数 -j 启动的线程数，在pgbench中启动多个线程 -t 进行多少的transaction -T 测试进行多少时间， -T和-t是互斥选项，只能二选一 -P 多少秒打印一次信息  只进行select测试 pgbench -Upostgres -c2 -j2 -T 120 -P5 -S -n  注释\n -S 只进行query测试 -n 跳过初始的vacuum ","id":7,"section":"posts","summary":"\u003cp\u003epgbench是postgresql进行压测的官方工具，熟悉这一工具的使用，对于后续数据库侧配置参数修改带来的影响，提供了客观的数据参考。\u003c/p\u003e","tags":null,"title":"pgbench使用初步","uri":"https://hseagle.github.io/2021/08/pg-pgbench/","year":"2021"},{"content":"PostgreSQL中锁机制及其原理\nPostgreSQL版本\u0026gt;9.6, 可以使用更为精简的查询\nselect pid, query_start, usename, pg_blocking_pids(pid) as blocked_by, query as blocked_query from pg_stat_activity where cardinality(pg_blocking_pids(pid)) \u0026gt; 0; ","id":8,"section":"posts","summary":"\u003cp\u003ePostgreSQL中锁机制及其原理\u003c/p\u003e","tags":null,"title":"PG死锁检测","uri":"https://hseagle.github.io/2021/07/pg-locks/","year":"2021"},{"content":"PostgreSQL有多种高可用的方案选择，在功能性和易用性两者平衡的角度来看, Patroni无疑是最成功的一款，本节会主要介绍一下patroni的安装配置和其背后基本原理。\npatronictl edit-config  patronictl reload ","id":9,"section":"posts","summary":"\u003cp\u003ePostgreSQL有多种高可用的方案选择，在功能性和易用性两者平衡的角度来看, Patroni无疑是最成功的一款，本节会主要介绍一下patroni的安装配置和其背后基本原理。\u003c/p\u003e","tags":["ha"],"title":"Patroni--首选的PG HA方案","uri":"https://hseagle.github.io/2021/07/patroni/","year":"2021"},{"content":"Citus是PostgreSQL目前已知水平扩容的插件中最成功的一款， 而且在2019年微软收购了该公司，足以证明该扩展的成功和流行，收购后citus的功能依然保持开源，所以这是一款值得使用并同时值得花时间研究的软件。\n多CN节点部署， 数据同步, 不建议在不同的CN对同一个DB进行DDL操作。\n由于在开源版本中，没有对多CN部署进行显式支持，现在琢磨出来的办法，虽然支持多点写入，但有如下限制。\n 支持同时对不同的数据库进行数据操作，同一个数据库由同一个CN路由进来 同一个库的数据，不要通过多个CN进行更改，但可以通过多个CN进行查询 CN之间的元数据不会自动同步，需要手工操作，其中最为关键的是 sequence 值的维护  dump表定义 pg_dump -Upostgres -ddemo -s -n 'yourschemaname' \u0026gt; /tmp/schemaname.sql  导入表定义 psql -Upostgres -ddemo -f /tmp/schenaname.sql  同步citus元数据 重要的元数据表\n pg_dist_partition pg_dist_shard pg_dist_placement pg_dist_node pg_dist_node_metadata  create extension dblink; insert into pg_dist_partition select * from dblink('host=localhost user=demo dbname=test', 'select * from pg_dist_partition') as a(logicalrelid regclass, partmethod char, partkey text, colocationid int, repmodel char) on conflict(logicalrelid) do nothing; --从另一个CN中导入pg_dist_shard中差异的部分 insert into pg_dist_shard select * from dblink('host=localhost user=demo dbname=test', 'select * from pg_dist_shard') as a(logicalrelid regclass, shardid bigint, shardstorage char, shardminvalue text, shardmaxvalue text) on conflict(shardid) do nothing; insert into pg_dist_placement select * from dblink('host=localhost user=demo dbname=test', 'select * from pg_dist_placement') as a(placementid bigint, shareid bigint, shardstate int, shardlength bigint, groupid int) on conflict(placementid) do nothing;  如果只针对某一张表进行元数据同步，可以采用如下步骤\nselect * from pg_dist_partition where logicalrelid::text like '%tablename%'; select * pg_dist_shard where logicalrelid='tablename'::regclass; select * from pg_dist_placement where shardid=shardid select format('alter table %s drop column xxx', table_name) from citus_shards where table_name like 'xxx%' and node_name=xxx;  元数据同步的最后，是设置sequence，在PG中，如果向表中插入记录的时候，已经指定了sequence字段所在的值，那么对应的sequence值不会自动更新，这时需要手工维护。\nselect setval('pg_catalog.pg_dist_shardid_seq', (SELECT MAX(shardid)+1 AS max_shard_id FROM pg_dist_shard), true); select setval('pg_catalog.pg_dist_placement_placementid_seq', (SELECT MAX(placementid)+1 AS max_placement_id FROM pg_dist_placement), true); select setval('pg_catalog.pg_dist_groupid_seq', (SELECT MAX(groupid)+1 AS max_group_id FROM pg_dist_node), true); select setval('pg_catalog.pg_dist_node_nodeid_seq', (SELECT MAX(nodeid)+1 AS max_node_id FROM pg_dist_node), true); select setval('pg_catalog.pg_dist_colocationid_seq', (SELECT MAX(colocationid)+1 AS max_colocation_id FROM pg_dist_colocation), true);  查看某个sequence的当前值， 在pg 11.2之后，可以把sequence看做普通的表进行查询\nselect * from pg_dist_shardid_seq; ","id":10,"section":"posts","summary":"\u003cp\u003eCitus是PostgreSQL目前已知水平扩容的插件中最成功的一款， 而且在2019年微软收购了该公司，足以证明该扩展的成功和流行，收购后citus的功能依然保持开源，所以这是一款值得使用并同时值得花时间研究的软件。\u003c/p\u003e","tags":["citus"],"title":"Citus扩展","uri":"https://hseagle.github.io/2021/07/pg-extension-citus/","year":"2021"},{"content":"SQL查询性能优化方法汇总\n","id":11,"section":"posts","summary":"\u003cp\u003eSQL查询性能优化方法汇总\u003c/p\u003e","tags":null,"title":"SQL查询性能优化","uri":"https://hseagle.github.io/2021/07/pg-sql-optimization/","year":"2021"},{"content":"PostgreSQL需要进行简单的配置才能允许用户从远程进行链接，本节会讲述涉及到的主要步骤。\n用户创建 create user birobot with encrypted password '123456';  上述语句创建了用户bitrobot, 密码设置为123456\n修改PostgreSQL服务器监听地址 打开postgresql.conf, 将监听地址修改为要监听的IP地址， \u0026lsquo;*\u0026lsquo;表示对所有的ip进行监听, 初始化安装时默认的监听地址是localhost。\nlisten_address = '*'  修改pg_hba.conf pg_hba.conf 文件用于设置用户可以从哪里进行访问，以及允许的认证方式是啥。\n#type database user address method host all all 192.168.56.0/24 trust host all all 192.168.0.0/16 md5  上述两条配置的含义解释如下\n 允许用户从子网192.168.56.0/24的网段进行访问，不需要密码验证 允许用户从子网192.168.0.0/16网段进行访问，需要进行密码验证  先定义的规则先生效，后续无法覆盖。\n远程链接测试 psql -Upostgres -dpostgres -h 192.158.56.112 -p 5432 ","id":12,"section":"posts","summary":"\u003cp\u003ePostgreSQL需要进行简单的配置才能允许用户从远程进行链接，本节会讲述涉及到的主要步骤。\u003c/p\u003e","tags":["PG安装"],"title":"PG远程链接","uri":"https://hseagle.github.io/2021/07/pg-remote-access/","year":"2021"},{"content":"本节涉及PostgreSQL的安装和运行， PostgreSQL历史悠久，Linux的各大发行版都对其支持友好，基本上都有编译好的二进制包直接可供下载安装。如果想亲自体验一下PostgreSQL的源码编译过程，那么就下载源码进行DIY，过程也不复杂。\n 源码安装 编译步骤 假设已经安装好gcc, g++以及make\n./configure make sudo make install  初始化 adduser postgres mkdir /usr/local/pgsql/data chown postgres /usr/local/pgsql/data su - postgres /usr/local/pgsql/bin/initdb -D /usr/local/pgsql/data /usr/local/pgsql/bin/pg_ctl -D /usr/local/pgsql/data -l logfile start /usr/local/pgsql/bin/createdb test /usr/local/pgsql/bin/psql test  安装结果验证 ps -ef|grep -i post sudo netstat -antpl|grep -i 5432  使用默认账户链接\npsql -Upostgres -dpostgres  CentOS7下安装 yum install postgresql13 postgresql13-server sudo systemctl enable postgresql-13 sudo /usr/pgsql-13/bin/postgresql-13-setup initdb sudo systemctl start postgresql-13  CentOS7下离线安装 以postgresql 13为例，找到安装包下载地址。https://download.postgresql.org/pub/repos/yum/13/redhat/，如果是在linux下可能采用lftp打开该地址，执行如下指令下载\nlftp https://download.postgresql.org/pub/repos/yum/13/redhat/rhel-7.12-x86_64/ mirror . /tmp/pg13_installer  下载完成之后，将安装包上传到目标机器，采用如下指令安装\nsudo yum -y install libicu sudo yum -y localinstall postgresql13-libs-13.2-1PGDG.rhel7.x86_64.rpm sudo yum -y localinstall ./postgresql13-13.2-1PGDG.rhel7.x86_64.rpm ./postgresql13-server-13.2-1PGDG.rhel7.x86_64.rpm sudo yum -y localinstall postgresql13-contrib-13.2-1PGDG.rhel7.x86_64.rpm sudo yum -y localinstall python3-psycopg2-2.8.5-1.rhel7.x86_64.rpm pg_partman_13-4.4.1-1.rhel7.x86_64.rpm pg_repack13-1.4.6-1.rhel7.x86_64.rpm  postgresql默认的数据目录是 /var/lib/pgsql/13/data, 如果要更换默认的文件夹， 需要修改文件 /usr/lib/systemd/system/postgresql-13.service 比如下面示例中，就将数据目录更换到 /pgsql/13/data。\n如果不更改默认指定目录，可以直接跳到数据库初始化步骤。\nEnvironment=PGDATA=/pgsql/13/data/  修改完成后执行\nsudo systemctl daemon-reload  数据库初始化 sudo /usr/pgsql-13/bin/postgresql-13-setup initdb  GUI BeeKeeper\n","id":13,"section":"posts","summary":"\u003cp\u003e本节涉及PostgreSQL的安装和运行， PostgreSQL历史悠久，Linux的各大发行版都对其支持友好，基本上都有编译好的二进制包直接可供下载安装。如果想亲自体验一下PostgreSQL的源码编译过程，那么就下载源码进行DIY，过程也不复杂。\u003c/p\u003e","tags":["PG安装"],"title":"PostgreSQL安装和运行","uri":"https://hseagle.github.io/2021/07/pg-install/","year":"2021"},{"content":"数据库过去是，现在是，将来肯定也是互联网技术中的热点和重点( 有押注的意味 ), 在开源数据中，以功能论PostgreSQL无疑是最强的，自从2014年以来，在db-engines.com排名中始终稳定在第4,声誉积分不断抬升，和SqlServer积分不断下滑趋势相比，很有可能在2-3年后， PostgreSQL会进入排名的top3。\n 基于如上判断，在日常工作中会尽量使用PostgreSQL, 并将积累的一些经验记录下来，以便总结和查询。\n","id":14,"section":"posts","summary":"\u003cp\u003e数据库过去是，现在是，将来肯定也是互联网技术中的热点和重点( \u003cstrong\u003e有押注的意味\u003c/strong\u003e ), 在开源数据中，以功能论PostgreSQL无疑是最强的，自从2014年以来，在db-engines.com排名中始终稳定在第4,声誉积分不断抬升，和SqlServer积分不断下滑趋势相比，很有可能在2-3年后， PostgreSQL会进入排名的top3。\u003c/p\u003e","tags":null,"title":"PG的明天值得期待","uri":"https://hseagle.github.io/2021/07/my-first-post/","year":"2021"}],"tags":[{"title":"citus","uri":"https://hseagle.github.io/tags/citus/"},{"title":"crawler","uri":"https://hseagle.github.io/tags/crawler/"},{"title":"ha","uri":"https://hseagle.github.io/tags/ha/"},{"title":"Materialize","uri":"https://hseagle.github.io/tags/materialize/"},{"title":"PG安装","uri":"https://hseagle.github.io/tags/pg%E5%AE%89%E8%A3%85/"},{"title":"PG逻辑复制","uri":"https://hseagle.github.io/tags/pg%E9%80%BB%E8%BE%91%E5%A4%8D%E5%88%B6/"},{"title":"psycopg2","uri":"https://hseagle.github.io/tags/psycopg2/"},{"title":"高可用","uri":"https://hseagle.github.io/tags/%E9%AB%98%E5%8F%AF%E7%94%A8/"}]}